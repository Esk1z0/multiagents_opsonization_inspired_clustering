{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b890a7e4",
   "metadata": {},
   "source": [
    "TODO: INTRO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d81b759",
   "metadata": {},
   "source": [
    "## Datasets seleccionados\n",
    "\n",
    "Para la validación experimental del algoritmo de clustering propuesto se han seleccionado los datasets **Iris** y **Wine**, ambos ampliamente utilizados como benchmarks en la literatura científica sobre clustering y aprendizaje no supervisado.\n",
    "\n",
    "### Iris\n",
    "El dataset Iris contiene 150 instancias descritas por 4 variables numéricas continuas, distribuidas en 3 clases reales. Su tamaño reducido y estructura bien estudiada lo convierten en un conjunto de datos idóneo para validar el comportamiento inicial de algoritmos de clustering y facilitar la interpretación de los resultados.\n",
    "\n",
    "### Wine\n",
    "El dataset Wine está compuesto por 178 instancias con 13 variables numéricas, también organizadas en 3 clases reales. Presenta una mayor dimensionalidad y complejidad que Iris, lo que permite evaluar la robustez del algoritmo frente a espacios de características más ricos.\n",
    "\n",
    "Ambos datasets incluyen etiquetas reales que **no se utilizan durante el proceso de clustering**, sino exclusivamente para la evaluación posterior mediante métricas externas, siguiendo el enfoque estándar en aprendizaje no supervisado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bb29fb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_wine\n",
    "\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "wine = load_wine()\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c5a314",
   "metadata": {},
   "source": [
    "## Métricas de evaluación\n",
    "\n",
    "La evaluación del rendimiento del algoritmo se realiza combinando métricas externas e internas, con el objetivo de analizar tanto la correspondencia con las clases reales como la calidad estructural de los clusters obtenidos.\n",
    "\n",
    "### Métricas externas\n",
    "\n",
    "**Adjusted Rand Index (ARI)**  \n",
    "Se utiliza como métrica principal para medir la similitud entre el clustering obtenido y las etiquetas reales. El índice está ajustado por azar, lo que permite una comparación robusta entre diferentes configuraciones y evita sesgos derivados de asignaciones aleatorias.\n",
    "\n",
    "**Normalized Mutual Information (NMI)**  \n",
    "Se emplea como métrica principal complementaria al ARI. Evalúa la cantidad de información compartida entre la partición obtenida y las clases reales, y es especialmente adecuada para comparar particiones independientemente de la permutación de etiquetas.\n",
    "\n",
    "### Métricas internas\n",
    "\n",
    "**Silhouette Score**  \n",
    "Se utiliza como métrica interna de apoyo para evaluar la cohesión interna de los clusters y su separación relativa, sin hacer uso de información externa. Permite analizar la calidad geométrica de la partición resultante.\n",
    "\n",
    "**Davies–Bouldin Index**  \n",
    "Se emplea como métrica interna complementaria al Silhouette Score. Mide la relación entre la dispersión intra-cluster y la separación inter-cluster, siendo valores más bajos indicativos de una mejor estructura de clustering.\n",
    "\n",
    "La combinación de métricas externas e internas permite una evaluación más completa del algoritmo, evitando depender de un único criterio y alineándose con las prácticas habituales en la literatura científica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef52be0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "ari = adjusted_rand_score(y_true, y_pred)\n",
    "nmi = normalized_mutual_info_score(y_true, y_pred)\n",
    "sil = silhouette_score(X, y_pred)\n",
    "db = davies_bouldin_score(X, y_pred)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
