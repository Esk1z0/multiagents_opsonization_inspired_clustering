{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b890a7e4",
   "metadata": {},
   "source": [
    "# OIC-Grid: Clustering multiagente\n",
    "\n",
    "**Asignatura:** Sistemas Multiagente \n",
    "**Autor:** Juan Esteban Rincón Marín\n",
    "**Objetivo:** Evaluar un algoritmo de clustering inspirado en el proceso de opsonización del sistema inmune sobre datasets clásicos, utilizando métricas externas e internas estándar. Se ha dado con el nombre tan original de **Opsozation-Inspired Clustering**, abreviado en **OIC**\n",
    "\n",
    "Este notebook contiene **toda la implementación y evaluación**, organizada por secciones temáticas para facilitar su lectura y evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d81b759",
   "metadata": {},
   "source": [
    "## Datasets seleccionados\n",
    "\n",
    "Para la validación experimental del algoritmo de clustering propuesto se han seleccionado los datasets **Iris** y **Wine**, ambos ampliamente utilizados como benchmarks en la literatura científica sobre clustering y aprendizaje no supervisado.\n",
    "\n",
    "### Iris\n",
    "El dataset Iris contiene 150 instancias descritas por 4 variables numéricas continuas, distribuidas en 3 clases reales. Su tamaño reducido y estructura bien estudiada lo convierten en un conjunto de datos idóneo para validar el comportamiento inicial de algoritmos de clustering y facilitar la interpretación de los resultados.\n",
    "\n",
    "### Wine\n",
    "El dataset Wine está compuesto por 178 instancias con 13 variables numéricas, también organizadas en 3 clases reales. Presenta una mayor dimensionalidad y complejidad que Iris, lo que permite evaluar la robustez del algoritmo frente a espacios de características más ricos.\n",
    "\n",
    "Ambos datasets incluyen etiquetas reales que **no se utilizan durante el proceso de clustering**, sino exclusivamente para la evaluación posterior mediante métricas externas, siguiendo el enfoque estándar en aprendizaje no supervisado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c5a314",
   "metadata": {},
   "source": [
    "## Métricas de evaluación\n",
    "\n",
    "La evaluación del rendimiento del algoritmo se realiza combinando métricas externas e internas, con el objetivo de analizar tanto la correspondencia con las clases reales como la calidad estructural de los clusters obtenidos.\n",
    "\n",
    "### Métricas externas\n",
    "\n",
    "**Adjusted Rand Index (ARI)**  \n",
    "Se utiliza como métrica principal para medir la similitud entre el clustering obtenido y las etiquetas reales. El índice está ajustado por azar, lo que permite una comparación robusta entre diferentes configuraciones y evita sesgos derivados de asignaciones aleatorias.\n",
    "\n",
    "**Normalized Mutual Information (NMI)**  \n",
    "Se emplea como métrica principal complementaria al ARI. Evalúa la cantidad de información compartida entre la partición obtenida y las clases reales, y es especialmente adecuada para comparar particiones independientemente de la permutación de etiquetas.\n",
    "\n",
    "### Métricas internas\n",
    "\n",
    "**Silhouette Score**  \n",
    "Se utiliza como métrica interna de apoyo para evaluar la cohesión interna de los clusters y su separación relativa, sin hacer uso de información externa. Permite analizar la calidad geométrica de la partición resultante.\n",
    "\n",
    "**Davies–Bouldin Index**  \n",
    "Se emplea como métrica interna complementaria al Silhouette Score. Mide la relación entre la dispersión intra-cluster y la separación inter-cluster, siendo valores más bajos indicativos de una mejor estructura de clustering.\n",
    "\n",
    "La combinación de métricas externas e internas permite una evaluación más completa del algoritmo, evitando depender de un único criterio y alineándose con las prácticas habituales en la literatura científica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7791b27",
   "metadata": {},
   "source": [
    "# 1. Imports y configuración global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a17be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import product\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from copy import deepcopy\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "import matplotlib as mpl\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    adjusted_rand_score,\n",
    "    normalized_mutual_info_score,\n",
    ")\n",
    "\n",
    "# CONSTANTES GLOBALES\n",
    "\n",
    "UNASSIGNED = -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9040192",
   "metadata": {},
   "source": [
    "# 2. Implementación mínima del algoritmo OIC con su calculo de metricas online y la aplicación de metricas internas y externas\n",
    "En esta sección se incluyen la definición de funciones de ayuda, dataclasses y la definición de la clase del algoritmo con su función fit().\n",
    "Posteriormente se definen funciones para calcular metricas offline y metricas online del algortimo, asi como la funcion fit_predict()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbab3e41",
   "metadata": {},
   "source": [
    "## 2.1. Utilidades geométricas y operaciones sobre el grid\n",
    "En esta sección se agrupan funciones auxiliares **independientes del algoritmo**, relacionadas con:\n",
    "- distancias\n",
    "- vecindarios\n",
    "- movimiento en grid\n",
    "- búsqueda de celdas libres\n",
    "\n",
    "No contienen lógica de clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5fe66098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chebyshev_distance(p1: Tuple[int, int], p2: Tuple[int, int]) -> int:\n",
    "    \"\"\"Calcula la distancia de Chebyshev entre dos posiciones.\"\"\"\n",
    "    # Distancia L inf para vecindarios tipo Moore.\n",
    "    return max(abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
    "\n",
    "\n",
    "def get_neighborhood(center: Tuple[int, int], radius: int, grid) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Devuelve las celdas válidas dentro de un radio Chebyshev.\"\"\"\n",
    "    # Explora el cuadrado (2r+1)x(2r+1) alrededor del centro.\n",
    "    cx, cy = center\n",
    "    cells: List[Tuple[int, int]] = []\n",
    "    for dx in range(-radius, radius + 1):\n",
    "        for dy in range(-radius, radius + 1):\n",
    "            pos = (cx + dx, cy + dy)\n",
    "            if grid.is_valid(pos):\n",
    "                cells.append(pos)\n",
    "    return cells\n",
    "\n",
    "\n",
    "def ordered_objects_in_cells(\n",
    "    cells: List[Tuple[int, int]],\n",
    "    grid,\n",
    "    objects: List\n",
    ") -> List:\n",
    "    \"\"\"Obtiene los objetos presentes en las celdas en orden determinista.\"\"\"\n",
    "    # Orden de lectura por filas: (y, x).\n",
    "    sorted_cells = sorted(cells, key=lambda pos: (pos[1], pos[0]))\n",
    "\n",
    "    obj_by_id = {obj.object_id: obj for obj in objects}\n",
    "    found: List = []\n",
    "\n",
    "    for cell in sorted_cells:\n",
    "        obj_id = grid.get_cell(cell)\n",
    "        if obj_id is not None and obj_id in obj_by_id:\n",
    "            found.append(obj_by_id[obj_id])\n",
    "\n",
    "    return found\n",
    "\n",
    "\n",
    "def random_walk_step_8dir(\n",
    "    pos: Tuple[int, int],\n",
    "    grid,\n",
    "    rng: np.random.Generator\n",
    ") -> Tuple[int, int]:\n",
    "    \"\"\"Da un paso aleatorio válido en 8 direcciones.\"\"\"\n",
    "    # Movimiento exploratorio sin objetivo.\n",
    "    directions = [(-1, -1), (-1, 0), (-1, 1),\n",
    "                  (0, -1),           (0, 1),\n",
    "                  (1, -1),  (1, 0),  (1, 1)]\n",
    "\n",
    "    valid_moves: List[Tuple[int, int]] = []\n",
    "    x, y = pos\n",
    "    for dx, dy in directions:\n",
    "        npos = (x + dx, y + dy)\n",
    "        if grid.is_valid(npos):\n",
    "            valid_moves.append(npos)\n",
    "\n",
    "    if not valid_moves:\n",
    "        return pos\n",
    "\n",
    "    return valid_moves[int(rng.integers(0, len(valid_moves)))]\n",
    "\n",
    "\n",
    "def greedy_step_minimize_dinf(\n",
    "    current: Tuple[int, int],\n",
    "    target: Tuple[int, int],\n",
    "    grid\n",
    ") -> Tuple[int, int]:\n",
    "    \"\"\"Da un paso que minimiza la distancia de Chebyshev al objetivo.\"\"\"\n",
    "    # Movimiento reactivo hacia el objetivo más cercano.\n",
    "    directions = [(-1, -1), (-1, 0), (-1, 1),\n",
    "                  (0, -1),           (0, 1),\n",
    "                  (1, -1),  (1, 0),  (1, 1)]\n",
    "\n",
    "    best_pos = current\n",
    "    best_dist = chebyshev_distance(current, target)\n",
    "\n",
    "    cx, cy = current\n",
    "    for dx, dy in directions:\n",
    "        npos = (cx + dx, cy + dy)\n",
    "        if grid.is_valid(npos):\n",
    "            d = chebyshev_distance(npos, target)\n",
    "            if d < best_dist:\n",
    "                best_dist = d\n",
    "                best_pos = npos\n",
    "\n",
    "    return best_pos\n",
    "\n",
    "\n",
    "def nearest_free_cell_by_increasing_radius(\n",
    "    center: Tuple[int, int],\n",
    "    grid,\n",
    "    max_radius: int = 50\n",
    ") -> Optional[Tuple[int, int]]:\n",
    "    \"\"\"Busca la celda libre más cercana ampliando el radio progresivamente.\"\"\"\n",
    "    # Búsqueda radial determinista alrededor del centro.\n",
    "    for r in range(0, max_radius + 1):\n",
    "        cells = get_neighborhood(center, r, grid)\n",
    "        cells.sort(key=lambda p: (chebyshev_distance(p, center), p[1], p[0]))\n",
    "\n",
    "        for cell in cells:\n",
    "            if grid.is_free(cell):\n",
    "                return cell\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46113e39",
   "metadata": {},
   "source": [
    "## 2.2. Entidades del sistema multiagente\n",
    "Aquí se definen las estructuras de datos que representan el estado del sistema:\n",
    "- Objetos a clasificar\n",
    "- Balizas (beacons)\n",
    "- Agentes (marcadores y transportadores)\n",
    "- Grid y estado global\n",
    "\n",
    "No se ejecuta el algoritmo en esta sección.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e1888b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Beacon:\n",
    "    \"\"\"Baliza que representa un clúster y su prototipo.\"\"\"\n",
    "    cluster_id: int\n",
    "    grid_pos: Tuple[int, int]\n",
    "    prototype: np.ndarray\n",
    "    count: int = 1\n",
    "\n",
    "    def update_prototype(self, new_object: np.ndarray) -> None:\n",
    "        \"\"\"Actualiza el prototipo usando media incremental.\"\"\"\n",
    "        self.count += 1\n",
    "        self.prototype += (new_object - self.prototype) / self.count\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GridObject:\n",
    "    \"\"\"Objeto de datos situado en el grid.\"\"\"\n",
    "    object_id: int\n",
    "    features: np.ndarray\n",
    "    grid_pos: Tuple[int, int]\n",
    "    label: int = 0  # 0 significa sin asignar\n",
    "    discarded: bool = False # Esto evita que se vuelva a recoger\n",
    "\n",
    "\n",
    "class Grid:\n",
    "    \"\"\"Grid 2D que almacena la ocupación por celda.\"\"\"\n",
    "    \n",
    "    def __init__(self, width: int, height: int):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        # occupancy[y][x] contiene object_id o None\n",
    "        self.occupancy: List[List[Optional[int]]] = [\n",
    "            [None for _ in range(width)] for _ in range(height)\n",
    "        ]\n",
    "\n",
    "    def is_valid(self, pos: Tuple[int, int]) -> bool:\n",
    "        \"\"\"Comprueba si una posición está dentro del grid.\"\"\"\n",
    "        x, y = pos\n",
    "        return 0 <= x < self.width and 0 <= y < self.height\n",
    "\n",
    "    def is_free(self, pos: Tuple[int, int]) -> bool:\n",
    "        \"\"\"Indica si una celda válida está libre.\"\"\"\n",
    "        if not self.is_valid(pos):\n",
    "            return False\n",
    "        x, y = pos\n",
    "        return self.occupancy[y][x] is None\n",
    "\n",
    "    def set_cell(self, pos: Tuple[int, int], obj_id: Optional[int]) -> None:\n",
    "        \"\"\"Ocupa o libera una celda del grid.\"\"\"\n",
    "        x, y = pos\n",
    "        self.occupancy[y][x] = obj_id\n",
    "\n",
    "    def get_cell(self, pos: Tuple[int, int]) -> Optional[int]:\n",
    "        \"\"\"Devuelve el object_id almacenado en una celda.\"\"\"\n",
    "        x, y = pos\n",
    "        return self.occupancy[y][x]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MarkerAgent:\n",
    "    \"\"\"Agente que crea balizas y etiqueta objetos.\"\"\"\n",
    "    agent_id: int\n",
    "    grid_pos: Tuple[int, int]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TransporterAgent:\n",
    "    \"\"\"Agente que transporta objetos entre celdas.\"\"\"\n",
    "    agent_id: int\n",
    "    grid_pos: Tuple[int, int]\n",
    "    carrying: Optional[int] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae3857",
   "metadata": {},
   "source": [
    "## 2.3. Algoritmo OIC-Grid\n",
    "Esta sección implementa el núcleo del algoritmo de clustering multiagente.\n",
    "Incluye la dinámica de los agentes, la creación y uso de balizas y la lógica\n",
    "de asignación de etiquetas.\n",
    "\n",
    "No incluye métricas ni evaluación experimental.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "547b2330",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OICGrid:\n",
    "    \"\"\"Clustering inspirado en opsonización sobre un grid 2D.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        grid_scale: float = 4.0,\n",
    "        object_radius: int = 1,\n",
    "        beacon_radius: int = 5,\n",
    "        local_beacon_cap: int = 3,\n",
    "        n_marker_agents: int = 5,\n",
    "        n_transporter_agents: int = 5,\n",
    "        seed_object_placement: int = 42,\n",
    "        seed_agent_walk: int = 43,\n",
    "        seed_tau_calculator: int = 44,\n",
    "        tau_percentile: int = 15,\n",
    "        tau_sample_ratio: float = 1.0\n",
    "    ):\n",
    "        \"\"\"Configura el grid, los radios, la capacidad local, los agentes y las semillas.\"\"\"\n",
    "        self.lambda_grid = grid_scale\n",
    "        self.r_obj = object_radius\n",
    "        self.r_beacon = beacon_radius\n",
    "        self.k_local = local_beacon_cap\n",
    "\n",
    "        self.n_markers = n_marker_agents\n",
    "        self.n_transporters = n_transporter_agents\n",
    "\n",
    "        self.rng_place = np.random.default_rng(seed_object_placement)\n",
    "        self.rng_walk = np.random.default_rng(seed_agent_walk)\n",
    "        self.rng_tau = np.random.default_rng(seed_tau_calculator)\n",
    "\n",
    "        self.objects: List[GridObject] = []\n",
    "        self.beacons: List[Beacon] = []\n",
    "        self.grid: Optional[Grid] = None\n",
    "        self.markers: List[MarkerAgent] = []\n",
    "        self.transporters: List[TransporterAgent] = []\n",
    "        self.tau: float = 0.0\n",
    "        self.tau_percentile: int = tau_percentile\n",
    "        self.tau_sample_ratio: float = tau_sample_ratio\n",
    "\n",
    "        self.states = []\n",
    "\n",
    "    def normalize(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normaliza las features con z-score.\"\"\"\n",
    "        return StandardScaler().fit_transform(X)\n",
    "\n",
    "    def compute_tau(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        percentile: float = 15.0,\n",
    "        sample_ratio: float = 1.0,\n",
    "        rng: Optional[np.random.Generator] = None,\n",
    "    ) -> float:\n",
    "        \"\"\"Calcula τ como percentil de distancias usando una fracción de pares.\"\"\"\n",
    "        n = len(X)\n",
    "        pairs = [(i, j) for i in range(n) for j in range(i + 1, n)]\n",
    "\n",
    "        if sample_ratio < 1.0:\n",
    "            rng = rng or np.random.default_rng()\n",
    "            pairs = rng.choice(pairs, size=int(len(pairs) * sample_ratio), replace=False)\n",
    "\n",
    "        d = [np.linalg.norm(X[i] - X[j]) for i, j in pairs]\n",
    "        return float(np.percentile(d, percentile))\n",
    "\n",
    "\n",
    "    def init_grid(self) -> Grid:\n",
    "        \"\"\"Crea el grid y posiciona los objetos.\"\"\"\n",
    "        n = len(self.objects)\n",
    "        size = int(self.lambda_grid * n)\n",
    "        w = int(np.ceil(np.sqrt(size)))\n",
    "        h = int(np.ceil(size / w))\n",
    "\n",
    "        grid = Grid(w, h)\n",
    "        cells = [(x, y) for x in range(w) for y in range(h)]\n",
    "        self.rng_place.shuffle(cells)\n",
    "\n",
    "        for obj, pos in zip(self.objects, cells):\n",
    "            obj.grid_pos = pos\n",
    "            grid.set_cell(pos, obj.object_id)\n",
    "\n",
    "        return grid\n",
    "\n",
    "    def init_agents(self) -> None:\n",
    "        \"\"\"Inicializa marcadores y transportadores.\"\"\"\n",
    "        for i in range(self.n_markers):\n",
    "            pos = (\n",
    "                self.rng_place.integers(0, self.grid.width),\n",
    "                self.rng_place.integers(0, self.grid.height),\n",
    "            )\n",
    "            self.markers.append(MarkerAgent(i, pos))\n",
    "\n",
    "        for i in range(self.n_transporters):\n",
    "            pos = (\n",
    "                self.rng_place.integers(0, self.grid.width),\n",
    "                self.rng_place.integers(0, self.grid.height),\n",
    "            )\n",
    "            self.transporters.append(TransporterAgent(i, pos))\n",
    "\n",
    "    def _visible_beacons(self, pos: Tuple[int, int]) -> List[Beacon]:\n",
    "        \"\"\"Devuelve las balizas visibles desde una posición.\"\"\"\n",
    "        return [\n",
    "            b for b in self.beacons\n",
    "            if chebyshev_distance(b.grid_pos, pos) <= self.r_beacon\n",
    "        ]\n",
    "\n",
    "    def _create_beacon(self, obj: GridObject) -> Beacon:\n",
    "        \"\"\"Crea una nueva baliza asociada a un objeto.\"\"\"\n",
    "        beacon = Beacon(\n",
    "            cluster_id=len(self.beacons) + 1,\n",
    "            grid_pos=obj.grid_pos,\n",
    "            prototype=obj.features.copy(),\n",
    "        )\n",
    "        self.beacons.append(beacon)\n",
    "        return beacon\n",
    "\n",
    "    def _marker_step(self, marker: MarkerAgent) -> None:\n",
    "        \"\"\"Ejecuta un paso de un marcador.\"\"\"\n",
    "        cells = get_neighborhood(marker.grid_pos, self.r_obj, self.grid)\n",
    "        objs = ordered_objects_in_cells(cells, self.grid, self.objects)\n",
    "\n",
    "        unlabeled = [o for o in objs if o.label == 0 and not o.discarded]\n",
    "        if not unlabeled:\n",
    "            marker.grid_pos = random_walk_step_8dir(marker.grid_pos, self.grid, self.rng_walk)\n",
    "            return\n",
    "\n",
    "        obj = unlabeled[0]\n",
    "        visibles = self._visible_beacons(obj.grid_pos)\n",
    "\n",
    "        if not visibles:\n",
    "            obj.label = self._create_beacon(obj).cluster_id\n",
    "        else:\n",
    "            dists = [np.linalg.norm(obj.features - b.prototype) for b in visibles]\n",
    "            idx = int(np.argmin(dists))\n",
    "            closest = visibles[idx]\n",
    "\n",
    "            if dists[idx] <= self.tau or len(visibles) >= self.k_local:\n",
    "                obj.label = closest.cluster_id\n",
    "                closest.update_prototype(obj.features)\n",
    "            else:\n",
    "                obj.label = self._create_beacon(obj).cluster_id\n",
    "\n",
    "        marker.grid_pos = random_walk_step_8dir(marker.grid_pos, self.grid, self.rng_walk)\n",
    "\n",
    "    def _transporter_step(self, transporter: TransporterAgent) -> None:\n",
    "        \"\"\"Ejecuta un paso de un transportador.\"\"\"\n",
    "        if transporter.carrying is None:\n",
    "            cells = get_neighborhood(transporter.grid_pos, self.r_obj, self.grid)\n",
    "            objs = ordered_objects_in_cells(cells, self.grid, self.objects)\n",
    "            labeled = [o for o in objs if o.label != 0 and not o.discarded]\n",
    "\n",
    "            if not labeled:\n",
    "                transporter.grid_pos = random_walk_step_8dir(\n",
    "                    transporter.grid_pos, self.grid, self.rng_walk\n",
    "                )\n",
    "                return\n",
    "\n",
    "            obj = labeled[0]\n",
    "            transporter.carrying = obj.object_id\n",
    "            self.grid.set_cell(obj.grid_pos, None)\n",
    "\n",
    "        else:\n",
    "            obj = self.objects[transporter.carrying]\n",
    "            beacon = next(b for b in self.beacons if b.cluster_id == obj.label)\n",
    "\n",
    "            if chebyshev_distance(transporter.grid_pos, beacon.grid_pos) > self.r_beacon:\n",
    "                transporter.grid_pos = random_walk_step_8dir(\n",
    "                    transporter.grid_pos, self.grid, self.rng_walk\n",
    "                )\n",
    "                return\n",
    "\n",
    "            cell = nearest_free_cell_by_increasing_radius(beacon.grid_pos, self.grid)\n",
    "            if cell is None:\n",
    "                transporter.grid_pos = random_walk_step_8dir(\n",
    "                    transporter.grid_pos, self.grid, self.rng_walk\n",
    "                )\n",
    "                return\n",
    "\n",
    "            transporter.grid_pos = greedy_step_minimize_dinf(\n",
    "                transporter.grid_pos, cell, self.grid\n",
    "            )\n",
    "\n",
    "            if transporter.grid_pos == cell:\n",
    "                obj.grid_pos = cell\n",
    "                obj.discarded = True\n",
    "                self.grid.set_cell(cell, obj.object_id)\n",
    "                transporter.carrying = None\n",
    "\n",
    "\n",
    "    def fit(\n",
    "            self,\n",
    "            X: np.ndarray,\n",
    "            iterations: int = 500,\n",
    "            record_states: bool = True,\n",
    "            record_every: int = 1,\n",
    "        ) -> \"OICGrid\":\n",
    "            \"\"\"Entrena el algoritmo durante un número fijo de iteraciones.\"\"\"\n",
    "            Xn = self.normalize(X)\n",
    "            self.tau = self.compute_tau(Xn, percentile = self.tau_percentile, sample_ratio = self.tau_sample_ratio, rng= self.rng_tau)\n",
    "\n",
    "            self.objects = [GridObject(i, Xn[i], (0, 0)) for i in range(len(Xn))]\n",
    "            self.grid = self.init_grid()\n",
    "            self.init_agents()\n",
    "\n",
    "            agents = self.markers + self.transporters\n",
    "\n",
    "            if record_states:\n",
    "                self.states.append({\n",
    "                    \"objects\": deepcopy(self.objects),\n",
    "                    \"beacons\": deepcopy(self.beacons),\n",
    "                    \"markers\": deepcopy(self.markers),\n",
    "                    \"transporters\": deepcopy(self.transporters),\n",
    "                    \"grid_size\": (self.grid.width, self.grid.height),\n",
    "                })\n",
    "\n",
    "            for it in range(iterations):\n",
    "                for a in agents:\n",
    "                    if isinstance(a, MarkerAgent):\n",
    "                        self._marker_step(a)\n",
    "                    else:\n",
    "                        self._transporter_step(a)\n",
    "\n",
    "                if record_states and (it % record_every == 0):\n",
    "                    self.states.append({\n",
    "                        \"objects\": deepcopy(self.objects),\n",
    "                        \"beacons\": deepcopy(self.beacons),\n",
    "                        \"markers\": deepcopy(self.markers),\n",
    "                        \"transporters\": deepcopy(self.transporters),\n",
    "                        \"grid_size\": (self.grid.width, self.grid.height),\n",
    "                    })\n",
    "\n",
    "            return self\n",
    "\n",
    "    def get_labels(self) -> np.ndarray:\n",
    "        \"\"\"Devuelve las etiquetas finales.\"\"\"\n",
    "        return np.array([o.label for o in self.objects])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b40f377",
   "metadata": {},
   "source": [
    "## 2.4. Métricas de evaluación del clustering\n",
    "En esta sección se implementan las métricas utilizadas para evaluar los resultados:\n",
    "- Métricas externas (ARI, NMI)\n",
    "- Métricas internas (Silhouette, Davies–Bouldin)\n",
    "\n",
    "Las métricas se calculan **ignorando los objetos no asignados (-1)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cf3367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(X, y_pred, y_true=None):\n",
    "    \"\"\"Calcula métricas offline con política cerrada de no asignados.\"\"\"\n",
    "    X = np.asarray(X)\n",
    "    y_pred = np.asarray(y_pred, dtype=int)\n",
    "\n",
    "    mask = (y_pred != UNASSIGNED)\n",
    "    n = len(y_pred)\n",
    "    n_assigned = int(mask.sum())\n",
    "    coverage_final = n_assigned / n if n > 0 else 0.0\n",
    "\n",
    "    out = {\n",
    "        \"coverage_final\": coverage_final,\n",
    "        \"n_assigned\": n_assigned,\n",
    "        \"silhouette\": np.nan,\n",
    "        \"davies_bouldin\": np.nan,\n",
    "        \"ari\": np.nan,\n",
    "        \"nmi\": np.nan,\n",
    "    }\n",
    "\n",
    "    if n_assigned < 2:\n",
    "        return out\n",
    "\n",
    "    X_a = X[mask]\n",
    "    y_a = y_pred[mask]\n",
    "    k = len(np.unique(y_a))\n",
    "    \n",
    "    # metricas internas\n",
    "    if k >= 2:\n",
    "        out[\"silhouette\"] = float(silhouette_score(X_a, y_a))\n",
    "        out[\"davies_bouldin\"] = float(davies_bouldin_score(X_a, y_a))\n",
    "    \n",
    "    # metricas externas\n",
    "    if y_true is not None:\n",
    "        y_true = np.asarray(y_true)\n",
    "        if k >= 2:\n",
    "            out[\"ari\"] = float(adjusted_rand_score(y_true[mask], y_a))\n",
    "            out[\"nmi\"] = float(normalized_mutual_info_score(y_true[mask], y_a))\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbab425",
   "metadata": {},
   "source": [
    "## 2.5. Métricas online durante la ejecución\n",
    "Además de las métricas finales, se registran métricas durante la ejecución\n",
    "del algoritmo para analizar su dinámica interna, tales como:\n",
    "- cobertura de clasificación\n",
    "- tasa de cambio de etiquetas\n",
    "- movimiento de objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74588561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_online_log(states, n: int):\n",
    "    \"\"\"Construye métricas online a partir de los estados guardados.\"\"\"\n",
    "    log = {\n",
    "        \"coverage\": [],\n",
    "        \"relabel_rate\": [],\n",
    "        \"move_rate\": [],\n",
    "    }\n",
    "\n",
    "    prev_labels = None\n",
    "    prev_pos = None\n",
    "\n",
    "    for t, st in enumerate(states):\n",
    "        objs = st[\"objects\"]\n",
    "        labels = np.array(\n",
    "            [o.label if o.label != 0 else UNASSIGNED for o in objs],\n",
    "            dtype=int\n",
    "        )\n",
    "        coverage = float(np.mean(labels != UNASSIGNED))\n",
    "        log[\"coverage\"].append(coverage)\n",
    "\n",
    "        if prev_labels is None:\n",
    "            log[\"relabel_rate\"].append(0.0)\n",
    "        else:\n",
    "            log[\"relabel_rate\"].append(float(np.mean(labels != prev_labels)))\n",
    "\n",
    "        pos = {o.object_id: o.grid_pos for o in objs}\n",
    "        if prev_pos is None:\n",
    "            log[\"move_rate\"].append(0.0)\n",
    "        else:\n",
    "            moved = sum(1 for i in pos if pos[i] != prev_pos.get(i, pos[i]))\n",
    "            log[\"move_rate\"].append(float(moved / n))\n",
    "\n",
    "        prev_labels = labels\n",
    "        prev_pos = pos\n",
    "    return log\n",
    "\n",
    "def _pad_or_truncate_labels(y_pred: np.ndarray, n: int) -> np.ndarray:\n",
    "    \"\"\"Asegura longitud n rellenando con -1 o truncando.\"\"\"\n",
    "    y = np.full(n, UNASSIGNED, dtype=int)\n",
    "    m = min(n, len(y_pred))\n",
    "    y[:m] = y_pred[:m]\n",
    "    return y\n",
    "\n",
    "def fit_predict(\n",
    "    X: np.ndarray,\n",
    "    params: dict,\n",
    "    seed: int,\n",
    "    return_online: bool = False,\n",
    "):\n",
    "    \"\"\"Ejecuta el algoritmo y devuelve etiquetas finales y métricas online opcionales.\"\"\"\n",
    "    X = np.asarray(X)\n",
    "    if X.ndim != 2:\n",
    "        raise ValueError(\"X debe ser 2D (n_samples, n_features).\")\n",
    "    n = X.shape[0]\n",
    "    p = dict(params)\n",
    "    iterations = int(p.pop(\"iterations\", 500))\n",
    "    record_every = int(p.pop(\"record_every\", 1))\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    algo = OICGrid(\n",
    "        **p,\n",
    "        seed_object_placement=seed,\n",
    "        seed_agent_walk=seed + 1,\n",
    "        seed_tau_calculator=seed +1\n",
    "    )\n",
    "\n",
    "    if return_online:\n",
    "        algo.fit(X, iterations=iterations, record_states=True, record_every=record_every)\n",
    "    else:\n",
    "        algo.fit(X, iterations=iterations, record_states=False)\n",
    "\n",
    "    labels_0 = np.asarray(algo.get_labels(), dtype=int)\n",
    "    y_pred = np.where(labels_0 == 0, UNASSIGNED, labels_0)\n",
    "\n",
    "    if y_pred.shape[0] != n:\n",
    "        y_pred = _pad_or_truncate_labels(y_pred, n)\n",
    "\n",
    "    online_log = None\n",
    "    if return_online:\n",
    "        online_log = build_online_log(algo.states, n)\n",
    "\n",
    "    return y_pred.astype(int), online_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278fa210",
   "metadata": {},
   "source": [
    "# 3. Pipeline experimental y grid search\n",
    "\n",
    "Implementación del pipeline completo para búsqueda sistemática de hiperparámetros óptimos mediante grid search con validación robusta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba474bca",
   "metadata": {},
   "source": [
    "## 3.1. Construcción del leaderboard\n",
    "\n",
    "Funciones para ejecutar el grid search completo:\n",
    "- Expansión del grid de parámetros en todas las combinaciones posibles\n",
    "- Ejecución de cada configuración con 30 semillas (seeds 0-29)\n",
    "- Cálculo de métricas offline (ARI, NMI, Silhouette, Davies-Bouldin)\n",
    "- Agregación de resultados: media y desviación estándar por configuración\n",
    "\n",
    "**Nota**: Las métricas externas (ARI, NMI) se calculan únicamente sobre objetos asignados, excluyendo aquellos con etiqueta -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b612cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_n_seeds(X, y_true, params, seeds):\n",
    "    \"\"\"Ejecuta múltiples seeds y agrega métricas (media, desviación y mediana).\"\"\"\n",
    "    runs = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        try:\n",
    "            y_pred, _ = fit_predict(X, params, seed, return_online=False)\n",
    "            metrics = compute_metrics(X, y_pred, y_true)\n",
    "            runs.append({\"seed\": seed, \"metrics\": metrics})\n",
    "        except Exception as e:\n",
    "            runs.append({\"seed\": seed, \"error\": str(e)})\n",
    "\n",
    "    ok = [r for r in runs if \"metrics\" in r]\n",
    "\n",
    "    def agg(key):\n",
    "        vals = [r[\"metrics\"][key] for r in ok if not np.isnan(r[\"metrics\"][key])]\n",
    "        if not vals:\n",
    "            return np.nan, np.nan, np.nan\n",
    "        return (\n",
    "            float(np.mean(vals)),\n",
    "            float(np.std(vals)),\n",
    "            float(np.median(vals)),\n",
    "        )\n",
    "\n",
    "    summary = {\n",
    "        \"silhouette_mean\": agg(\"silhouette\")[0],\n",
    "        \"silhouette_std\": agg(\"silhouette\")[1],\n",
    "        \"silhouette_median\": agg(\"silhouette\")[2],\n",
    "\n",
    "        \"davies_bouldin_mean\": agg(\"davies_bouldin\")[0],\n",
    "        \"davies_bouldin_std\": agg(\"davies_bouldin\")[1],\n",
    "        \"davies_bouldin_median\": agg(\"davies_bouldin\")[2],\n",
    "\n",
    "        \"ari_mean\": agg(\"ari\")[0],\n",
    "        \"ari_std\": agg(\"ari\")[1],\n",
    "        \"ari_median\": agg(\"ari\")[2],\n",
    "\n",
    "        \"nmi_mean\": agg(\"nmi\")[0],\n",
    "        \"nmi_std\": agg(\"nmi\")[1],\n",
    "        \"nmi_median\": agg(\"nmi\")[2],\n",
    "\n",
    "        \"coverage_mean\": agg(\"coverage_final\")[0],\n",
    "        \"coverage_std\": agg(\"coverage_final\")[1],\n",
    "        \"coverage_median\": agg(\"coverage_final\")[2],\n",
    "\n",
    "        \"n_runs_ok\": len(ok),\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"runs\": runs,\n",
    "        \"summary\": summary,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3950a04",
   "metadata": {},
   "source": [
    "Aqui ahora vamnos a preparar todo para el grid search de nivel 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7068d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaderboard_row(params: dict, summary: dict, extra: dict | None = None) -> dict:\n",
    "    \"\"\"Construye una fila plana para tabla/CSV.\"\"\"\n",
    "    row = {\n",
    "        \"params\": str(params),\n",
    "\n",
    "        \"ari_mean\": summary.get(\"ari_mean\", np.nan),\n",
    "        \"ari_std\": summary.get(\"ari_std\", np.nan),\n",
    "        \"ari_median\": summary.get(\"ari_median\", np.nan),\n",
    "\n",
    "        \"nmi_mean\": summary.get(\"nmi_mean\", np.nan),\n",
    "        \"nmi_std\": summary.get(\"nmi_std\", np.nan),\n",
    "        \"nmi_median\": summary.get(\"nmi_median\", np.nan),\n",
    "\n",
    "        \"silhouette_mean\": summary.get(\"silhouette_mean\", np.nan),\n",
    "        \"silhouette_std\": summary.get(\"silhouette_std\", np.nan),\n",
    "        \"silhouette_median\": summary.get(\"silhouette_median\", np.nan),\n",
    "\n",
    "        \"davies_bouldin_mean\": summary.get(\"davies_bouldin_mean\", np.nan),\n",
    "        \"davies_bouldin_std\": summary.get(\"davies_bouldin_std\", np.nan),\n",
    "        \"davies_bouldin_median\": summary.get(\"davies_bouldin_median\", np.nan),\n",
    "\n",
    "        \"coverage_mean\": summary.get(\"coverage_mean\", np.nan),\n",
    "        \"coverage_std\": summary.get(\"coverage_std\", np.nan),\n",
    "        \"coverage_median\": summary.get(\"coverage_median\", np.nan),\n",
    "\n",
    "        \"n_runs_ok\": summary.get(\"n_runs_ok\", 0),\n",
    "    }\n",
    "\n",
    "    if extra:\n",
    "        row.update(extra)\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def expand_param_grid(param_grid: dict) -> list[dict]:\n",
    "    \"\"\"Genera combinaciones de un param_grid tipo dict[str, list].\"\"\"\n",
    "    keys = list(param_grid.keys())\n",
    "    combos = product(*[param_grid[k] for k in keys])\n",
    "    return [dict(zip(keys, c)) for c in combos]\n",
    "\n",
    "\n",
    "def build_leaderboard(X, y_true, configs: list[dict], seeds: list[int], dataset_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Ejecuta configs×seeds y devuelve un dataframe ordenable.\"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for cid, params in enumerate(configs):\n",
    "        out = run_n_seeds(X, y_true, params, seeds)\n",
    "        row = leaderboard_row(\n",
    "            params=params,\n",
    "            summary=out[\"summary\"],\n",
    "            extra={\"dataset\": dataset_name, \"config_id\": cid}\n",
    "        )\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c1176",
   "metadata": {},
   "source": [
    "## 3.2. Filtrado y selección de configuraciones viables\n",
    "\n",
    "Funciones para identificar configuraciones con buen rendimiento y comportamiento estable:\n",
    "\n",
    "**Criterios de viabilidad**:\n",
    "- Coverage mínimo: ≥ 90% de objetos asignados\n",
    "- Estabilidad: ARI_std ≤ 0.10 (configurable)\n",
    "- Davies-Bouldin máximo (opcional)\n",
    "- Número de balizas máximo (opcional)\n",
    "\n",
    "**Ordenamiento**: Por ARI_mean (descendente), NMI_mean, Silhouette_mean, Davies-Bouldin_mean (ascendente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4edef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_configs(df: pd.DataFrame, top_k: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"Selecciona top configs con desempates cerrados.\"\"\"\n",
    "    df2 = df.sort_values(\n",
    "        [\"ari_mean\", \"nmi_mean\", \"silhouette_mean\", \"davies_bouldin_mean\"],\n",
    "        ascending=[False, False, False, True]\n",
    "    )\n",
    "    return df2.head(top_k)\n",
    "\n",
    "def filter_viable(df: pd.DataFrame,\n",
    "                  min_coverage: float = 0.90,\n",
    "                  max_db: float | None = None,\n",
    "                  max_ari_std: float | None = None,\n",
    "                  max_beacons_mean: float | None = None) -> pd.DataFrame:\n",
    "    \"\"\"Filtra configs inviables por cobertura/inestabilidad y criterios opcionales.\"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    out = out[out[\"coverage_mean\"] >= min_coverage]\n",
    "\n",
    "    if max_db is not None:\n",
    "        out = out[out[\"davies_bouldin_mean\"] <= max_db]\n",
    "\n",
    "    if max_ari_std is not None:\n",
    "        out = out[out[\"ari_std\"] <= max_ari_std]\n",
    "\n",
    "    if max_beacons_mean is not None and \"n_beacons_mean\" in out.columns:\n",
    "        out = out[out[\"n_beacons_mean\"] <= max_beacons_mean]\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bac016",
   "metadata": {},
   "source": [
    "## 3.3. Ejecución representativa con métricas online\n",
    "\n",
    "Funciones para ejecutar la mejor configuración con un run representativo (semilla mediana) y capturar métricas temporales:\n",
    "\n",
    "**Selección de semilla representativa**: Se ordena por ARI y se elige la semilla cuyo valor esté más cerca de la mediana.\n",
    "\n",
    "**Métricas online capturadas**:\n",
    "- **Coverage(t)**: Proporción de objetos asignados\n",
    "- **Relabel_rate(t)**: Proporción de cambios de etiqueta respecto a t-1\n",
    "- **Move_rate(t)**: Proporción de movimientos espaciales en el grid\n",
    "\n",
    "Estas métricas permiten analizar la dinámica de convergencia del algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f2d9a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_representative_seed(runs: list[dict], metric_key: str = \"ari\") -> int:\n",
    "    \"\"\"Elige la seed cuyo metric esté más cerca de la mediana.\"\"\"\n",
    "    ok = [r for r in runs if \"metrics\" in r and not np.isnan(r[\"metrics\"].get(metric_key, np.nan))]\n",
    "    if not ok:\n",
    "        return int(runs[0][\"seed\"])\n",
    "\n",
    "    vals = np.array([r[\"metrics\"][metric_key] for r in ok], dtype=float)\n",
    "    med = float(np.median(vals))\n",
    "\n",
    "    best = min(ok, key=lambda r: abs(r[\"metrics\"][metric_key] - med))\n",
    "    return int(best[\"seed\"])\n",
    "\n",
    "def run_config_with_online(X, y_true, params: dict, seeds: list[int], record_every: int = 5):\n",
    "    \"\"\"Repite seeds offline y genera online_log para una seed representativa.\"\"\"\n",
    "    out = run_n_seeds(X, y_true, params, seeds)\n",
    "    seed_rep = pick_representative_seed(out[\"runs\"], metric_key=\"ari\")\n",
    "\n",
    "    y_pred, online_log = fit_predict(\n",
    "        X,\n",
    "        params | {\"record_every\": record_every},\n",
    "        seed=seed_rep,\n",
    "        return_online=True\n",
    "    )\n",
    "\n",
    "    metrics_rep = compute_metrics(X, y_pred, y_true)\n",
    "    return out, seed_rep, metrics_rep, online_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bec5a36",
   "metadata": {},
   "source": [
    "## 3.4. Visualización de resultados\n",
    "\n",
    "Funciones para graficar métricas online y animar el proceso de clustering:\n",
    "\n",
    "**`plot_online_curves()`**: Genera gráficas de coverage y move_rate a lo largo del tiempo.\n",
    "\n",
    "**`animate()`**: Crea animación del grid mostrando:\n",
    "- Puntos coloreados por cluster\n",
    "- Cruces negras (balizas)\n",
    "- Triángulos azules (marcadores)\n",
    "- Cuadrados rojos (transportadores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d7629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_online_curves(online_log: dict):\n",
    "    \"\"\"Grafica coverage y move_rate para una ejecución representativa.\"\"\"\n",
    "    t = np.arange(len(online_log[\"coverage\"]))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(t, online_log[\"coverage\"])\n",
    "    plt.title(\"Coverage(t)\")\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(\"coverage\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(t, online_log[\"move_rate\"])\n",
    "    plt.title(\"Move rate(t)\")\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(\"move_rate\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def draw_state(ax, state):\n",
    "    \"\"\"Dibuja objetos, balizas y agentes.\"\"\"\n",
    "    ax.clear()\n",
    "\n",
    "    # Objetos\n",
    "    ox = [o.grid_pos[0] for o in state[\"objects\"]]\n",
    "    oy = [o.grid_pos[1] for o in state[\"objects\"]]\n",
    "    labels = [o.label for o in state[\"objects\"]]\n",
    "    ax.scatter(ox, oy, c=labels, cmap=\"tab10\", s=30, alpha=0.7)\n",
    "\n",
    "    # Balizas\n",
    "    if state[\"beacons\"]:\n",
    "        bx = [b.grid_pos[0] for b in state[\"beacons\"]]\n",
    "        by = [b.grid_pos[1] for b in state[\"beacons\"]]\n",
    "        ax.scatter(bx, by, c=\"black\", marker=\"x\", s=120, linewidths=2)\n",
    "\n",
    "    # Marcadores\n",
    "    mx = [m.grid_pos[0] for m in state[\"markers\"]]\n",
    "    my = [m.grid_pos[1] for m in state[\"markers\"]]\n",
    "    ax.scatter(mx, my, c=\"blue\", marker=\"^\", s=80)\n",
    "\n",
    "    # Transportadores\n",
    "    tx = [t.grid_pos[0] for t in state[\"transporters\"]]\n",
    "    ty = [t.grid_pos[1] for t in state[\"transporters\"]]\n",
    "    ax.scatter(tx, ty, c=\"red\", marker=\"s\", s=80)\n",
    "\n",
    "    w, h = state[\"grid_size\"]\n",
    "    ax.set_xlim(-1, w)\n",
    "    ax.set_ylim(-1, h)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "def animate(states, interval=200):\n",
    "    \"\"\"Animación inline del algoritmo.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    def update(i):\n",
    "        draw_state(ax, states[i])\n",
    "        ax.set_title(f\"Iteración {i}\")\n",
    "\n",
    "    anim = FuncAnimation(\n",
    "        fig,\n",
    "        update,\n",
    "        frames=len(states),\n",
    "        interval=interval\n",
    "    )\n",
    "\n",
    "    plt.close(fig)\n",
    "    return HTML(anim.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e303d9",
   "metadata": {},
   "source": [
    "# 4. Evaluación experimental en datasets benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f9fa57",
   "metadata": {},
   "source": [
    "## 4.1. Dataset Iris\n",
    "\n",
    "Aplicación del pipeline completo sobre el dataset Iris (150 instancias, 4 features, 3 clases):\n",
    "1. Grid search con 30 semillas por configuración\n",
    "2. Filtrado por viabilidad (coverage ≥ 0.90, ARI_std configurable)\n",
    "3. Selección de configuraciones top\n",
    "4. Ejecución representativa con métricas online\n",
    "5. Visualización animada (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1624a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset IRIS\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "# Definir seeds para robustez\n",
    "seeds = list(range(30))\n",
    "\n",
    "# Definir grid de hiperparámetros\n",
    "param_grid = {\n",
    "    \"grid_scale\": [4.0],\n",
    "    \"beacon_radius\": [6, 8, 12],\n",
    "    \"local_beacon_cap\": [3, 5, 8],\n",
    "    \"n_marker_agents\": [3, 10, 20],\n",
    "    \"n_transporter_agents\": [3, 10, 20],\n",
    "    \"tau_percentile\": [15, 25],\n",
    "    \"iterations\": [2500],\n",
    "}\n",
    "# Expandir combinaciones del grid\n",
    "configs = expand_param_grid(param_grid)\n",
    "\n",
    "# Ejecutar grid search y construir leaderboard\n",
    "df_lb = build_leaderboard(X_iris, y_iris, configs, seeds, dataset_name=\"iris\")\n",
    "# Ordenar por criterio cerrado de selección\n",
    "df_lb = df_lb.sort_values(\n",
    "    [\"ari_mean\", \"nmi_mean\", \"silhouette_mean\", \"davies_bouldin_mean\"],\n",
    "    ascending=[False, False, False, True]\n",
    ")\n",
    "\n",
    "# Guardar resultados para el paper\n",
    "df_lb.to_csv(\"leaderboard_iris.csv\", index=False)\n",
    "\n",
    "# Filtrar configuraciones inviables\n",
    "df_ok = filter_viable(df_lb, min_coverage=0.90, max_ari_std=0.10)\n",
    "\n",
    "# Seleccionar top 10 configuraciones\n",
    "df_top = select_top_configs(df_ok, top_k=10)\n",
    "df_top.to_csv(\"leaderboard_iris_top10.csv\", index=False)\n",
    "display(df_top)\n",
    "# Extraer mejor configuración\n",
    "best_params = eval(df_top.iloc[0][\"params\"])\n",
    "\n",
    "# Ejecutar run representativo con métricas online\n",
    "out, seed_rep, metrics_rep, online_log = run_config_with_online(\n",
    "    X_iris, y_iris, best_params, seeds, record_every=5\n",
    ")\n",
    "# Mostrar resultados finales\n",
    "print(\"Los mejores resultados corresponden a: \", seed_rep)\n",
    "display(metrics_rep)\n",
    "# Visualizar métricas online\n",
    "plot_online_curves(online_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85aa05f",
   "metadata": {},
   "source": [
    "## 4.2. Visualización animada del proceso (Iris)\n",
    "\n",
    "Animación del proceso de clustering usando la mejor configuración encontrada y la semilla representativa.\n",
    "\n",
    "Permite observar la dinámica espacial del algoritmo: exploración inicial, etiquetado, transporte y convergencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permitir animaciones grandes\n",
    "mpl.rcParams[\"animation.embed_limit\"] = 300  # MB\n",
    "\n",
    "# Mejor configuración\n",
    "best_params = eval(df_top.iloc[0][\"params\"])\n",
    "seed = seed_rep\n",
    "\n",
    "# Separar parámetros de init y fit\n",
    "iterations = best_params[\"iterations\"]\n",
    "init_params = {k: v for k, v in best_params.items() if k != \"iterations\"}\n",
    "\n",
    "# Ejecutar solo para visualización\n",
    "oic = OICGrid(\n",
    "    **init_params,\n",
    "    seed_object_placement=seed,\n",
    "    seed_agent_walk=seed,\n",
    "    seed_tau_calculator=seed,\n",
    ")\n",
    "\n",
    "oic.fit(\n",
    "    X_iris,\n",
    "    iterations=iterations,\n",
    "    record_states=True,\n",
    "    record_every=5,\n",
    ")\n",
    "\n",
    "# Animación\n",
    "animate(oic.states)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9046ec7",
   "metadata": {},
   "source": [
    "## 4.3. Dataset Wine\n",
    "\n",
    "Aplicación del mismo pipeline sobre Wine (178 instancias, 13 features, 3 clases).\n",
    "\n",
    "Mayor dimensionalidad que Iris permite evaluar robustez del algoritmo en espacios de características más complejos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf742a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset WINE\n",
    "wine = load_wine()\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target\n",
    "\n",
    "# Reutilizar seeds\n",
    "seeds = list(range(30))\n",
    "\n",
    "# Reutilizar mismo grid de parámetros\n",
    "configs = expand_param_grid(param_grid)\n",
    "\n",
    "# Ejecutar grid search\n",
    "df_lb_wine = build_leaderboard(X_wine, y_wine, configs, seeds, dataset_name=\"wine\")\n",
    "\n",
    "# Ordenar por criterio cerrado\n",
    "df_lb_wine = df_lb_wine.sort_values(\n",
    "    [\"ari_mean\", \"nmi_mean\", \"silhouette_mean\", \"davies_bouldin_mean\"],\n",
    "    ascending=[False, False, False, True]\n",
    ")\n",
    "\n",
    "# Guardar resultados\n",
    "df_lb_wine.to_csv(\"leaderboard_wine.csv\", index=False)\n",
    "\n",
    "# Filtrar configuraciones inviables\n",
    "df_ok_wine = filter_viable(df_lb_wine, min_coverage=0.90, max_ari_std=0.10)\n",
    "\n",
    "# Seleccionar top 10\n",
    "df_top_wine = select_top_configs(df_ok_wine, top_k=10)\n",
    "df_top_wine.to_csv(\"leaderboard_wine_top10.csv\", index=False)\n",
    "print(\"TOP 10 EJECUCIONES\")\n",
    "display(df_top_wine)\n",
    "\n",
    "# Extraer mejor configuración\n",
    "best_params_wine = eval(df_top_wine.iloc[0][\"params\"])\n",
    "\n",
    "# Ejecutar run representativo con métricas online\n",
    "out_w, seed_rep_w, metrics_rep_w, online_log_w = run_config_with_online(\n",
    "    X_wine, y_wine, best_params_wine, seeds, record_every=5\n",
    ")\n",
    "\n",
    "# Mostrar resultados finales\n",
    "print(\"Los mejores resultados corresponden a: \", seed_rep_w)\n",
    "display(metrics_rep_w)\n",
    "\n",
    "# Visualizar métricas online\n",
    "plot_online_curves(online_log_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be41c750",
   "metadata": {},
   "source": [
    "## 4.4. Visualización animada del proceso (Wine)\n",
    "\n",
    "Animación equivalente usando la mejor configuración para Wine.\n",
    "\n",
    "Permite comparar visualmente el comportamiento del algoritmo en datasets de distinta complejidad dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d00b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permitir animaciones grandes\n",
    "mpl.rcParams[\"animation.embed_limit\"] = 300  # MB\n",
    "\n",
    "# Mejor configuración para WINE\n",
    "best_params_wine = eval(df_top_wine.iloc[0][\"params\"])\n",
    "seed = seed_rep_w\n",
    "\n",
    "# Separar parámetros de init y fit\n",
    "iterations = best_params_wine[\"iterations\"]\n",
    "init_params = {k: v for k, v in best_params_wine.items() if k != \"iterations\"}\n",
    "\n",
    "# Ejecutar solo para visualización\n",
    "oic_wine = OICGrid(\n",
    "    **init_params,\n",
    "    seed_object_placement=seed,\n",
    "    seed_agent_walk=seed,\n",
    "    seed_tau_calculator=seed,\n",
    ")\n",
    "\n",
    "oic_wine.fit(\n",
    "    X_wine,\n",
    "    iterations=iterations,\n",
    "    record_states=True,\n",
    "    record_every=5,\n",
    ")\n",
    "\n",
    "# Animación\n",
    "animate(oic_wine.states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f108d7",
   "metadata": {},
   "source": [
    "## 4.5. Comparación con K-means baseline\n",
    "\n",
    "Evaluación comparativa con K-means para validar el rendimiento de OIC-Grid frente a un algoritmo de referencia establecido.\n",
    "\n",
    "**Configuración del baseline**:\n",
    "- K-means con K=3 (número de clases conocidas)\n",
    "- 30 inicializaciones aleatorias por run (n_init=30)\n",
    "- Inicialización k-means++\n",
    "- Máximo 300 iteraciones\n",
    "- Normalización z-score de los datos\n",
    "- Mismas 30 semillas que OIC-Grid\n",
    "\n",
    "**Nota**: K-means asigna todos los objetos (coverage=100%), mientras que OIC-Grid puede dejar objetos sin asignar basándose en criterios de similaridad. Esta diferencia se refleja en las métricas de coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "087fd358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    adjusted_rand_score,\n",
    "    normalized_mutual_info_score,\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    ")\n",
    "\n",
    "\n",
    "def eval_kmeans_summary(\n",
    "    X,\n",
    "    y_true,\n",
    "    k: int,\n",
    "    seeds=range(30),\n",
    "    dataset_name: str = \"\",\n",
    "):\n",
    "    \"\"\"Evalúa K-Means en múltiples seeds y devuelve métricas agregadas.\"\"\"\n",
    "    \n",
    "    # Normalización z-score\n",
    "    Xn = StandardScaler().fit_transform(X)\n",
    "\n",
    "    ari, nmi, sil, db = [], [], [], []\n",
    "\n",
    "    for seed in seeds:\n",
    "        km = KMeans(\n",
    "            n_clusters=k,\n",
    "            init=\"k-means++\",\n",
    "            n_init=30,\n",
    "            max_iter=300,\n",
    "            random_state=seed,\n",
    "        )\n",
    "\n",
    "        y_pred = km.fit_predict(Xn)\n",
    "\n",
    "        ari.append(adjusted_rand_score(y_true, y_pred))\n",
    "        nmi.append(normalized_mutual_info_score(y_true, y_pred))\n",
    "        sil.append(silhouette_score(Xn, y_pred))\n",
    "        db.append(davies_bouldin_score(Xn, y_pred))\n",
    "\n",
    "    summary = {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"algorithm\": \"kmeans\",\n",
    "        \"k\": k,\n",
    "\n",
    "        \"ari_mean\": np.mean(ari),\n",
    "        \"ari_std\": np.std(ari, ddof=1),\n",
    "\n",
    "        \"nmi_mean\": np.mean(nmi),\n",
    "        \"nmi_std\": np.std(nmi, ddof=1),\n",
    "\n",
    "        \"silhouette_mean\": np.mean(sil),\n",
    "        \"silhouette_std\": np.std(sil, ddof=1),\n",
    "\n",
    "        \"davies_bouldin_mean\": np.mean(db),\n",
    "        \"davies_bouldin_std\": np.std(db, ddof=1),\n",
    "\n",
    "        \"n_runs\": len(seeds),\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame([summary])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b10b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>k</th>\n",
       "      <th>ari_mean</th>\n",
       "      <th>ari_std</th>\n",
       "      <th>nmi_mean</th>\n",
       "      <th>nmi_std</th>\n",
       "      <th>silhouette_mean</th>\n",
       "      <th>silhouette_std</th>\n",
       "      <th>davies_bouldin_mean</th>\n",
       "      <th>davies_bouldin_std</th>\n",
       "      <th>n_runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iris</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>3</td>\n",
       "      <td>0.620135</td>\n",
       "      <td>2.258405e-16</td>\n",
       "      <td>0.659487</td>\n",
       "      <td>1.129203e-16</td>\n",
       "      <td>0.459948</td>\n",
       "      <td>5.646013e-17</td>\n",
       "      <td>0.833595</td>\n",
       "      <td>2.258405e-16</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset algorithm  k  ari_mean       ari_std  nmi_mean       nmi_std  \\\n",
       "0    iris    kmeans  3  0.620135  2.258405e-16  0.659487  1.129203e-16   \n",
       "\n",
       "   silhouette_mean  silhouette_std  davies_bouldin_mean  davies_bouldin_std  \\\n",
       "0         0.459948    5.646013e-17             0.833595        2.258405e-16   \n",
       "\n",
       "   n_runs  \n",
       "0      30  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "df_kmeans_iris = eval_kmeans_summary(\n",
    "    iris.data,\n",
    "    iris.target,\n",
    "    k=3,\n",
    "    seeds=range(30),\n",
    "    dataset_name=\"iris\",\n",
    ")\n",
    "\n",
    "display(df_kmeans_iris)\n",
    "df_kmeans_iris.to_csv(\"kmeans_iris_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56d2143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>k</th>\n",
       "      <th>ari_mean</th>\n",
       "      <th>ari_std</th>\n",
       "      <th>nmi_mean</th>\n",
       "      <th>nmi_std</th>\n",
       "      <th>silhouette_mean</th>\n",
       "      <th>silhouette_std</th>\n",
       "      <th>davies_bouldin_mean</th>\n",
       "      <th>davies_bouldin_std</th>\n",
       "      <th>n_runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wine</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>3</td>\n",
       "      <td>0.897495</td>\n",
       "      <td>1.129203e-16</td>\n",
       "      <td>0.875894</td>\n",
       "      <td>3.387608e-16</td>\n",
       "      <td>0.284859</td>\n",
       "      <td>1.129203e-16</td>\n",
       "      <td>1.389188</td>\n",
       "      <td>2.258405e-16</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset algorithm  k  ari_mean       ari_std  nmi_mean       nmi_std  \\\n",
       "0    wine    kmeans  3  0.897495  1.129203e-16  0.875894  3.387608e-16   \n",
       "\n",
       "   silhouette_mean  silhouette_std  davies_bouldin_mean  davies_bouldin_std  \\\n",
       "0         0.284859    1.129203e-16             1.389188        2.258405e-16   \n",
       "\n",
       "   n_runs  \n",
       "0      30  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wine = load_wine()\n",
    "\n",
    "df_kmeans_wine = eval_kmeans_summary(\n",
    "    wine.data,\n",
    "    wine.target,\n",
    "    k=3,\n",
    "    seeds=range(30),\n",
    "    dataset_name=\"wine\",\n",
    ")\n",
    "\n",
    "display(df_kmeans_wine)\n",
    "df_kmeans_wine.to_csv(\"kmeans_wine_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db5dcf",
   "metadata": {},
   "source": [
    "## 4.6. Análisis comparativo de resultados y conclusiones\n",
    "\n",
    "Se compara el algoritmo propuesto **OIC-Grid** con **K-means** como baseline, utilizando los datasets **Iris** y **Wine**, y evaluando mediante métricas externas (ARI, NMI), internas (Silhouette, Davies–Bouldin) y cobertura final.\n",
    "\n",
    "### Resultados cuantitativos\n",
    "\n",
    "**Iris**\n",
    "\n",
    "| Métrica | OIC-Grid | K-means |\n",
    "|--------|----------|---------|\n",
    "| ARI | 0.281 ± 0.051 | 0.620 |\n",
    "| NMI | 0.453 ± 0.033 | 0.660 |\n",
    "| Silhouette | -0.140 ± 0.049 | 0.460 |\n",
    "| Davies–Bouldin | 3.65 ± 1.05 | 0.83 |\n",
    "| Coverage | 99.9% | 100% |\n",
    "\n",
    "**Wine**\n",
    "\n",
    "| Métrica | OIC-Grid | K-means |\n",
    "|--------|----------|---------|\n",
    "| ARI | 0.297 ± 0.067 | 0.898 |\n",
    "| NMI | 0.489 ± 0.044 | 0.876 |\n",
    "| Silhouette | -0.515 ± 0.075 | 0.285 |\n",
    "| Davies–Bouldin | 13.99 ± 5.28 | 1.39 |\n",
    "| Coverage | 99.6% | 100% |\n",
    "\n",
    "En ambos datasets, **K-means supera claramente a OIC-Grid** en todas las métricas de calidad de clustering, especialmente en Wine, donde la mayor dimensionalidad amplifica las limitaciones del enfoque basado en grid 2D.\n",
    "\n",
    "### Interpretación\n",
    "\n",
    "La brecha observada se explica principalmente por:\n",
    "\n",
    "1. **Ventaja estructural del baseline**: K-means conoce el número de clusters a priori, mientras que OIC-Grid lo descubre de forma autónoma.\n",
    "2. **Optimización explícita vs reglas locales**: K-means minimiza directamente la varianza intra-cluster; OIC-Grid se basa en decisiones estigmérgicas locales.\n",
    "3. **Dependencia del grid 2D**: la organización espacial introduce distorsiones en la preservación de distancias semánticas, especialmente en espacios de alta dimensión.\n",
    "4. **Sensibilidad al umbral τ**: valores conservadores fragmentan clusters naturales; el percentil 25 mejora resultados frente a 15, pero no elimina el solapamiento.\n",
    "\n",
    "### Observaciones clave sobre OIC-Grid\n",
    "\n",
    "**Fortalezas**:\n",
    "- No requiere conocer K a priori.\n",
    "- Alta cobertura (>99%) y estabilidad entre seeds.\n",
    "- Proceso transparente y trazable mediante dinámica del grid.\n",
    "- Métricas online permiten analizar convergencia y comportamiento dinámico.\n",
    "\n",
    "**Limitaciones**:\n",
    "- Rendimiento cuantitativo inferior a K-means.\n",
    "- Silhouette negativo y Davies–Bouldin elevado indican solapamiento y baja separación.\n",
    "- El grid 2D actúa como cuello de botella semántico.\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "OIC-Grid no compite con K-means en rendimiento puro, pero valida una **propuesta descentralizada y explicable de clustering**, adecuada para escenarios donde **K es desconocido**, se prioriza **observabilidad del proceso** o se requiere **integración en sistemas multiagente o robóticos**. Su principal valor reside en el diseño y la dinámica del algoritmo, más que en la optimización directa de métricas estándar.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
